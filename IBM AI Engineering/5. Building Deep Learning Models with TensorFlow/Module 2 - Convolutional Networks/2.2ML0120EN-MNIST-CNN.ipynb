{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture\n",
    "\n",
    "The architecture of the network will be:\n",
    "\n",
    " - **Input** -> [batch_size,28,28,1] >> Apply 32 filter of [5x5]\n",
    " \n",
    " \n",
    " - **Convolutional layer 1**\n",
    "    - **Convolve Operation 1** -> [batch_size,28,28,32]\n",
    "    - **ReLU 1** -> [?,28,28,32]\n",
    "    - **Max Pooling 1** [?,14,14,32]\n",
    "\n",
    "\n",
    " - **Convolutional layer 2**\n",
    "     - **Convolve Operation 2** -> [?,14,14,64]\n",
    "     - **ReLU 2** -> [?,14,14,64]\n",
    "     - **Max Pooling 2** [?,7,7,64]\n",
    "\n",
    "\n",
    " - **Fully connected layer 3** -> [1x1024]\n",
    "     - **ReLU 3** -> [1x1024]\n",
    "     - **Dropout** -> [1x1024]\n",
    "\n",
    "\n",
    " - **Fully connected layer 4** -> [1x10]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial parameters\n",
    "\n",
    "Create general parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 28 #Width of the image in pixels\n",
    "height = 28 #Height of the image in pixels\n",
    "flat = width * height #Number of pixels in one image\n",
    "class_output = 10 #Number of possible classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32,shape=[None,flat],name='x_placeholder')\n",
    "y_ = tf.placeholder(dtype=tf.float32,shape=[None,class_output],name='y_gold_placeholder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting images of the data set to tensors\n",
    "\n",
    "The input image is a 28x28 pixels and 1 channel (grayscale)\n",
    "\n",
    "**We need to reshape the image to match this format:**\n",
    "\n",
    "Image = [batch_size, width, height, number of channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1]) #-1 in batch_size means any size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1: Convolutional layer\n",
    "\n",
    "Let's make out first convolutional layer\n",
    "\n",
    "### Convolve operation\n",
    "\n",
    "**Defining kernel weight and bias**\n",
    "\n",
    " - Kernel: 5x5\n",
    " - Input channels: 1\n",
    " - Feature maps: 32 => Number of filters applied on each image, like a depth, so transforms the output to [width,height,depth]\n",
    " \n",
    "Kernel of shape: [filter_height,filter_widht,in_channels,out_channels]\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/f4touwscxlis8f2bqjqg4u5zxftnyntc.png\" style=\"width:400px;height:200px;\" alt=\"HTML5 Icon\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,32],stddev=0.1)) #<- Weights it's just our kernel :D\n",
    "\n",
    "#Bias always equal to the number of outputs\n",
    "b_conv1 = tf.Variable(tf.constant(shape=[32],value=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolve operation with weights and biases**\n",
    "\n",
    "To create convolutional layer we use **tf.nn.conv2d** that computes 2D convolution given 4D input and filter tensors.\n",
    "\n",
    "Inputs:\n",
    " - Tensor of shape [batch, in_height, in_width, channels] => x : [batch_size,28,28,1]\n",
    " - A kernel of shape [filter_height, filter_width, in_channels, out_channels] => W_conv1 : [5,5,1,32]\n",
    " - stride which is [1,1,1,1]\n",
    " \n",
    "Process:\n",
    " - Change the filter to a 2D matrix with shape [5*5*1,32]\n",
    " - Extracts the image patches from the input tensor to a virtual tensor of shape [batch,28,28,5*5*1]\n",
    " - For each patch, right multiplies the filter matrix and the image patch vector\n",
    " \n",
    "Output:\n",
    " - A tensor (2D convolution) of size [batch_size,28,28,32]\n",
    "  - Notice that the output is like 32[28x28]images. Here 32 is considered as volume/depth of the output image\n",
    "  \n",
    "  <img src=\"https://ibm.box.com/shared/static/brosafd4eaii7sggpbeqwj9qmnk96hmx.png\" style=\"width:400px;height:200px;\" alt=\"HTML5 Icon\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convolve1 = tf.nn.conv2d(input=x_image,filter=W_conv1,strides=[1,1,1,1],padding='SAME') + b_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "\n",
    "Go through all outputs convolution layer and apply ReLU (turn negative values into 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(convolve1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling\n",
    "\n",
    "Use the max pooling, it'll reduce the output to [14,14,32]\n",
    "\n",
    "This is because max pooling is an operation that finds maximum values and simplifies the inputs using spacial correlations between them. \n",
    "\n",
    "- **Value:** The input => The previous ReLU output\n",
    "\n",
    "\n",
    "- **Kernel size:** 2x2 (halves the input)\n",
    "\n",
    " - Caution: It's defined as 'The size of the window for each dimension of the input tensor.' -> [2x2] => [1,2,2,1]\n",
    "\n",
    "\n",
    "- **Strides:** The sliding behaviour, 2 pixels everytime, thus no overlaping\n",
    "\n",
    "\n",
    "\n",
    "- **Padding:** SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/awyoq0e2r3hfx3n7xrvhw4y7gly683p4.png\" alt=\"HTML5 Icon\" style=\"width:400px;height:200px;\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool1 = tf.nn.max_pool(value=h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Layer Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = h_pool1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2: Convolutional layer\n",
    "\n",
    "### Convolve operation\n",
    "\n",
    "**Defining kernel weight and bias**\n",
    "\n",
    " - Kernel: 5x5\n",
    " - Input channels: 32 (from the 1st Conv Layer, we had 32 feature maps) \n",
    " - Feature maps: 64 => Number of filters applied on each image, like a depth, so transforms the output to [width,height,depth]\n",
    " \n",
    "**Notice:**\n",
    " - Input: [14x14x32]\n",
    " - Kernel: [5x5x32]\n",
    " - Filters: 64\n",
    "\n",
    "So the output convolutional layer would be [14,14,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,32,64],stddev=0.1)) #<- Weights it's just our kernel :D\n",
    "\n",
    "#Bias always equal to the number of outputs\n",
    "b_conv2 = tf.Variable(tf.constant(shape=[64],value=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolve operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolve2 = tf.nn.conv2d(input=layer1,filter=W_conv2,strides=[1,1,1,1],padding='SAME') + b_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv2 = tf.nn.relu(convolve2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_pool2 = tf.nn.max_pool(value=h_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Layer Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer2 = h_pool2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Convolutional Layer 2, which output is:\n",
    " - 64 matrix of 7x7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 3: Fully Connected Layer\n",
    "\n",
    "A Fully Connected Layer is needed to use the SoftMax and create the probabilities in the end. Fully connected layers take the high levels 'images' from previous layer, that is all 64 matrics, and convert them to an array (flatten)\n",
    "\n",
    "1. Eeach matrix [7x7] -> [49x1]\n",
    "2. All 64 matrics of [49,1] will connect into [3136x1]\n",
    "3. Connect the [3136x1] to [1024x1] \n",
    "    - The weights between them will be [3136,1024]\n",
    "    \n",
    "<img src=\"https://ibm.box.com/shared/static/hvbegd0lfr1maxpq2gpq3g8ibvk8d2eo.png\" alt=\"HTML5 Icon\" style=\"width:400px;height:200px;\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening layer \n",
    "\n",
    "So we catch the last layer and reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer2_matrix = tf.reshape(layer2,[-1,7*7*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and biases between layer 2 and 3 (in the fully connected layer)\n",
    "\n",
    "The 64 matrix of [7x7] => 3136\n",
    "The outputs to Softmax => 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = tf.Variable(tf.truncated_normal(shape=[7*7*64,1024],stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(value=0.1,shape=[1024]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcl3 = tf.matmul(layer2_matrix,W_fc1) + b_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_fc1 = tf.nn.relu(fcl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third layer complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer3 = h_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements for Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "It's a phase where the network 'forget' some features. Some units get's switched off randomly so that will not interact with the network. It prevents overfitting.\n",
    "\n",
    " - **keep prob:** A Placeholder of type float32\n",
    " - **x:** The layer to cause the droput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "layer3_drop = tf.nn.dropout(x=layer3,keep_prob=keep_prob) #Keep_prob is the dropout rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Fully Connected Layer 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 4: Readout layer (Softmax layer, output layer)\n",
    "\n",
    "A Softmax, fully connected layer for the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and biases\n",
    "\n",
    "In last layer, the CNN takes the high level filtered images and translate them into votes using softmax.\n",
    "\n",
    " - Input: 1024 neuron from the 3rd (fully connected) layer\n",
    " - Output: 10 possible classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = tf.Variable(tf.truncated_normal(shape=[1024,10],stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(value=0.1,shape=[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcl4 = tf.matmul(layer3_drop,W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax activation\n",
    "\n",
    "Softmax allows us to interpret the outputs of fcl4 as probabilities, so **y_conv** is a tensor of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_conv = tf.nn.softmax(fcl4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth Layer Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer4 = y_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the CNN\n",
    "\n",
    "0. Input - MNIST dataset\n",
    "1. Convolutional - ReLU - MaxPooling\n",
    "2. Convolutonal - ReLU - MaxPooling\n",
    "3. Fully Connected Layer w/dropout\n",
    "4. Readout Layer - Softmax - Fully connected\n",
    "5. Output - Classified Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions and train the model\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "We need to compare our output layer 4 tensor with the correct labels. We can use cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(layer4),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "\n",
    "It'll be done by an optimizer called Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define prediction\n",
    "\n",
    "Let's count some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of correct predictions\n",
    "correct_prediction = tf.equal(tf.argmax(layer4,1),tf.argmax(y_,1))\n",
    "\n",
    "#Accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightweight version\n",
    "\n",
    "Try 20.000 epochs for a really hardcore version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0 the training accuracy: 0.10\n",
      "At step 100 the training accuracy: 0.94\n",
      "At step 200 the training accuracy: 0.92\n",
      "At step 300 the training accuracy: 1.00\n",
      "At step 400 the training accuracy: 0.96\n",
      "At step 500 the training accuracy: 0.94\n",
      "At step 600 the training accuracy: 0.94\n",
      "At step 700 the training accuracy: 0.98\n",
      "At step 800 the training accuracy: 0.92\n",
      "At step 900 the training accuracy: 0.96\n",
      "At step 1000 the training accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "epochs = 1100\n",
    "batch_size = 50\n",
    "\n",
    "for step in range(epochs):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    feed = {x:batch[0],y_:batch[1],keep_prob:0.5} #Because of the dropout we need to specify the dropout rate\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0],y_:batch[1],keep_prob:1.0}) \n",
    "        print('At step %d the training accuracy: %.2f' %(step, train_accuracy))\n",
    "        \n",
    "    train_step.run(feed_dict=feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Print the evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy for the CNN model on test set is: 96.56\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy.eval(feed_dict={x : mnist.test.images, y_ : mnist.test.labels,keep_prob:1.0}) * 100\n",
    "\n",
    "print('The final accuracy for the CNN model on test set is: %.002f' % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
